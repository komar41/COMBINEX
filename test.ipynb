{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d46d7a94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Repo root: c:\\Users\\qshah\\Documents\\Spring 2026\\COMBINEX\n",
      "CUDA: True\n"
     ]
    }
   ],
   "source": [
    "# Cell 0\n",
    "import os, sys, random\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "REPO_ROOT = os.getcwd()   # or simply \".\"\n",
    "sys.path.insert(0, REPO_ROOT)\n",
    "\n",
    "print(\"Repo root:\", REPO_ROOT)\n",
    "print(\"CUDA:\", torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0d7f4d1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 1\n",
    "from omegaconf import OmegaConf\n",
    "from hydra import initialize, compose\n",
    "\n",
    "from torch.nn import functional as F\n",
    "\n",
    "from src.utils.dataset import get_dataset\n",
    "from src.datasets.dataset import DataInfo\n",
    "from src.utils.models import get_model\n",
    "\n",
    "# If you want to reuse your training pipeline:\n",
    "from src.oracles.train.train import Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fd0ff1af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Node\n",
      "citeseer\n"
     ]
    }
   ],
   "source": [
    "# Cell 2\n",
    "CFG_PATH = os.path.join(REPO_ROOT, \"config\", \"config.yaml\")  # adjust if different\n",
    "cfg = OmegaConf.load(CFG_PATH)\n",
    "\n",
    "with initialize(config_path=\"config\", version_base=\"1.3\"):\n",
    "    cfg = compose(\n",
    "        config_name=\"config\",\n",
    "        overrides=[\n",
    "            \"task=node\",\n",
    "            \"dataset=citeseer\",   # or cora / pubmed / etc\n",
    "        ],\n",
    "    )\n",
    "\n",
    "\n",
    "print(cfg.task.name)      # \"Node\"\n",
    "print(cfg.dataset.name)   # \"CiteSeer\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "24be0e5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda\n",
      "num_features: 3703\n",
      "num_classes: 6\n"
     ]
    }
   ],
   "source": [
    "# Cell 3\n",
    "\n",
    "def seed_everything(seed: int):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "\n",
    "seed_everything(int(cfg.general.seed))\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() and cfg.device == \"cuda\" else \"cpu\"\n",
    "print(\"Device:\", device)\n",
    "\n",
    "data = get_dataset(cfg.dataset.name, test_size=cfg.test_size)\n",
    "data = data.to(device)\n",
    "\n",
    "datainfo = DataInfo(cfg, data)  # note: your DataInfo deletes self.data internally\n",
    "print(\"num_features:\", datainfo.num_features)\n",
    "print(\"num_classes:\", datainfo.num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c400c158",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "name='CHEB', task='Node'\n",
      "Epoch:    0 Train Loss: 1.7756 Train Acc: 0.2015 Test Loss: 1.7727 Test Acc: 0.1892\n"
     ]
    },
    {
     "ename": "Error",
     "evalue": "You must call wandb.init() before wandb.log()",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mError\u001b[39m                                     Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[22]\u001b[39m\u001b[32m, line 9\u001b[39m\n\u001b[32m      2\u001b[39m oracle = OracleClass(\n\u001b[32m      3\u001b[39m     num_features=datainfo.num_features,\n\u001b[32m      4\u001b[39m     num_classes=datainfo.num_classes,\n\u001b[32m      5\u001b[39m     cfg=cfg,\n\u001b[32m      6\u001b[39m ).to(device)\n\u001b[32m      8\u001b[39m trainer = Trainer(cfg=cfg, dataset=data, model=oracle, loss=F.cross_entropy)\n\u001b[32m----> \u001b[39m\u001b[32m9\u001b[39m \u001b[43mtrainer\u001b[49m\u001b[43m.\u001b[49m\u001b[43mstart_training\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     11\u001b[39m oracle = trainer.model\n\u001b[32m     12\u001b[39m oracle.eval()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\qshah\\Documents\\Spring 2026\\COMBINEX\\src\\oracles\\train\\train.py:149\u001b[39m, in \u001b[36mTrainer.start_training\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    147\u001b[39m \ttest_loss, test_accuracy = \u001b[38;5;28mself\u001b[39m._test()\n\u001b[32m    148\u001b[39m \t\u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mEpoch: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m4d\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m Train Loss: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtrain_loss\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m Train Acc: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtrain_accuracy\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m Test Loss: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtest_loss\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m Test Acc: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtest_accuracy\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m149\u001b[39m \t\u001b[43mwandb\u001b[49m\u001b[43m.\u001b[49m\u001b[43mlog\u001b[49m\u001b[43m(\u001b[49m\u001b[43m{\u001b[49m\n\u001b[32m    150\u001b[39m \u001b[43m\t\t\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43moracle_train_loss\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loss\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdetach\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcpu\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    151\u001b[39m \u001b[43m\t\t\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43moracle_train_accuracy\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_accuracy\u001b[49m\u001b[43m.\u001b[49m\u001b[43mitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    152\u001b[39m \u001b[43m\t\t\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43moracle_test_loss\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_loss\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdetach\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcpu\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    153\u001b[39m \u001b[43m\t\t\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43moracle_test_accuracy\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_accuracy\u001b[49m\u001b[43m.\u001b[49m\u001b[43mitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    154\u001b[39m \u001b[43m\t\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    155\u001b[39m \tmetrics.loc[epoch] = [epoch, train_loss.detach().cpu().item(), train_accuracy.item(), test_loss.detach().cpu().item(), test_accuracy.item()]\n\u001b[32m    157\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m os.path.exists(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mdata/models\u001b[39m\u001b[33m\"\u001b[39m):\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\qshah\\Documents\\Spring 2026\\COMBINEX\\envs\\Lib\\site-packages\\wandb\\sdk\\lib\\preinit.py:36\u001b[39m, in \u001b[36mPreInitCallable.<locals>.preinit_wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m     35\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mpreinit_wrapper\u001b[39m(*args: Any, **kwargs: Any) -> Any:\n\u001b[32m---> \u001b[39m\u001b[32m36\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m wandb.Error(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mYou must call wandb.init() before \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m()\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mError\u001b[39m: You must call wandb.init() before wandb.log()"
     ]
    }
   ],
   "source": [
    "OracleClass = get_model(name=cfg.model.name, task=cfg.task.name)\n",
    "oracle = OracleClass(\n",
    "    num_features=datainfo.num_features,\n",
    "    num_classes=datainfo.num_classes,\n",
    "    cfg=cfg,\n",
    ").to(device)\n",
    "\n",
    "trainer = Trainer(cfg=cfg, dataset=data, model=oracle, loss=F.cross_entropy)\n",
    "trainer.start_training()\n",
    "\n",
    "oracle = trainer.model\n",
    "oracle.eval()\n",
    "\n",
    "print(\"Oracle ready.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5da0c14e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "envs",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
