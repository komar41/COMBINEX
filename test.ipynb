{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d46d7a94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Repo root: /Users/kazishahrukhomar/Documents/MISC/COMBINEX\n",
      "CUDA: False\n"
     ]
    }
   ],
   "source": [
    "# Cell 0\n",
    "import os, sys, random\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "REPO_ROOT = os.getcwd()   # or simply \".\"\n",
    "sys.path.insert(0, REPO_ROOT)\n",
    "\n",
    "print(\"Repo root:\", REPO_ROOT)\n",
    "print(\"CUDA:\", torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b4aae039",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"WANDB_MODE\"] = \"disabled\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0d7f4d1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 1\n",
    "from omegaconf import OmegaConf\n",
    "from hydra import initialize, compose\n",
    "\n",
    "from torch.nn import functional as F\n",
    "\n",
    "from src.utils.dataset import get_dataset\n",
    "from src.datasets.dataset import DataInfo\n",
    "from src.utils.models import get_model\n",
    "\n",
    "# If you want to reuse your training pipeline:\n",
    "from src.oracles.train.train import Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fd0ff1af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Node\n",
      "citeseer\n"
     ]
    }
   ],
   "source": [
    "# Cell 2\n",
    "CFG_PATH = os.path.join(REPO_ROOT, \"config\", \"config.yaml\")  # adjust if different\n",
    "cfg = OmegaConf.load(CFG_PATH)\n",
    "\n",
    "with initialize(config_path=\"config\", version_base=\"1.3\"):\n",
    "    cfg = compose(\n",
    "        config_name=\"config\",\n",
    "        overrides=[\n",
    "            \"task=node\",\n",
    "            \"dataset=citeseer\",   # or cora / pubmed / etc\n",
    "            \"device=cpu\",        # or cuda\n",
    "        ],\n",
    "    )\n",
    "\n",
    "\n",
    "print(cfg.task.name)      # \"Node\"\n",
    "print(cfg.dataset.name)   # \"CiteSeer\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "24be0e5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cpu\n",
      "num_features: 3703\n",
      "num_classes: 6\n"
     ]
    }
   ],
   "source": [
    "# Cell 3\n",
    "\n",
    "def seed_everything(seed: int):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "\n",
    "seed_everything(int(cfg.general.seed))\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() and cfg.device == \"cuda\" else \"cpu\"\n",
    "print(\"Device:\", device)\n",
    "\n",
    "data = get_dataset(cfg.dataset.name, test_size=cfg.test_size)\n",
    "data = data.to(device)\n",
    "\n",
    "datainfo = DataInfo(cfg, data)  # note: your DataInfo deletes self.data internally\n",
    "print(\"num_features:\", datainfo.num_features)\n",
    "print(\"num_classes:\", datainfo.num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c400c158",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "name='CHEB', task='Node'\n",
      "Epoch:    0 Train Loss: 1.7733 Train Acc: 0.2135 Test Loss: 1.7721 Test Acc: 0.2132\n",
      "Epoch:    1 Train Loss: 1.7711 Train Acc: 0.2041 Test Loss: 1.7660 Test Acc: 0.2012\n",
      "Epoch:    2 Train Loss: 1.7640 Train Acc: 0.2218 Test Loss: 1.7647 Test Acc: 0.2132\n",
      "Epoch:    3 Train Loss: 1.7569 Train Acc: 0.2440 Test Loss: 1.7589 Test Acc: 0.2177\n",
      "Epoch:    4 Train Loss: 1.7528 Train Acc: 0.2492 Test Loss: 1.7614 Test Acc: 0.2207\n",
      "Epoch:    5 Train Loss: 1.7488 Train Acc: 0.2350 Test Loss: 1.7498 Test Acc: 0.2342\n",
      "Epoch:    6 Train Loss: 1.7381 Train Acc: 0.2586 Test Loss: 1.7434 Test Acc: 0.2523\n",
      "Epoch:    7 Train Loss: 1.7350 Train Acc: 0.2564 Test Loss: 1.7426 Test Acc: 0.2402\n",
      "Epoch:    8 Train Loss: 1.7279 Train Acc: 0.2590 Test Loss: 1.7256 Test Acc: 0.2718\n",
      "Epoch:    9 Train Loss: 1.7186 Train Acc: 0.2714 Test Loss: 1.7303 Test Acc: 0.2568\n",
      "Epoch:   10 Train Loss: 1.7107 Train Acc: 0.2647 Test Loss: 1.7237 Test Acc: 0.2462\n",
      "Epoch:   11 Train Loss: 1.7039 Train Acc: 0.2744 Test Loss: 1.7163 Test Acc: 0.2462\n",
      "Epoch:   12 Train Loss: 1.6890 Train Acc: 0.2812 Test Loss: 1.7139 Test Acc: 0.2568\n",
      "Epoch:   13 Train Loss: 1.6849 Train Acc: 0.2617 Test Loss: 1.6913 Test Acc: 0.2583\n",
      "Epoch:   14 Train Loss: 1.6670 Train Acc: 0.2842 Test Loss: 1.6808 Test Acc: 0.2688\n",
      "Epoch:   15 Train Loss: 1.6636 Train Acc: 0.2910 Test Loss: 1.6673 Test Acc: 0.3018\n",
      "Epoch:   16 Train Loss: 1.6486 Train Acc: 0.2925 Test Loss: 1.6918 Test Acc: 0.2628\n",
      "Epoch:   17 Train Loss: 1.6355 Train Acc: 0.3019 Test Loss: 1.6765 Test Acc: 0.2658\n",
      "Epoch:   18 Train Loss: 1.6257 Train Acc: 0.3071 Test Loss: 1.6529 Test Acc: 0.3048\n",
      "Epoch:   19 Train Loss: 1.6121 Train Acc: 0.3143 Test Loss: 1.6570 Test Acc: 0.2688\n",
      "Epoch:   20 Train Loss: 1.5948 Train Acc: 0.3297 Test Loss: 1.6319 Test Acc: 0.3018\n",
      "Epoch:   21 Train Loss: 1.5813 Train Acc: 0.3316 Test Loss: 1.6390 Test Acc: 0.3243\n",
      "Epoch:   22 Train Loss: 1.5681 Train Acc: 0.3425 Test Loss: 1.6194 Test Acc: 0.3033\n",
      "Epoch:   23 Train Loss: 1.5515 Train Acc: 0.3455 Test Loss: 1.5988 Test Acc: 0.3243\n",
      "Epoch:   24 Train Loss: 1.5401 Train Acc: 0.3594 Test Loss: 1.5911 Test Acc: 0.3483\n",
      "Epoch:   25 Train Loss: 1.5054 Train Acc: 0.3737 Test Loss: 1.5944 Test Acc: 0.3243\n",
      "Epoch:   26 Train Loss: 1.4958 Train Acc: 0.3846 Test Loss: 1.5734 Test Acc: 0.3664\n",
      "Epoch:   27 Train Loss: 1.4851 Train Acc: 0.3868 Test Loss: 1.5787 Test Acc: 0.3559\n",
      "Epoch:   28 Train Loss: 1.4620 Train Acc: 0.3992 Test Loss: 1.5417 Test Acc: 0.3829\n",
      "Epoch:   29 Train Loss: 1.4460 Train Acc: 0.4139 Test Loss: 1.5278 Test Acc: 0.3844\n",
      "Epoch:   30 Train Loss: 1.4292 Train Acc: 0.4207 Test Loss: 1.5178 Test Acc: 0.3859\n",
      "Epoch:   31 Train Loss: 1.3936 Train Acc: 0.4331 Test Loss: 1.5077 Test Acc: 0.3964\n",
      "Epoch:   32 Train Loss: 1.3816 Train Acc: 0.4350 Test Loss: 1.4791 Test Acc: 0.4129\n",
      "Epoch:   33 Train Loss: 1.3589 Train Acc: 0.4579 Test Loss: 1.4724 Test Acc: 0.3934\n",
      "Epoch:   34 Train Loss: 1.3368 Train Acc: 0.4602 Test Loss: 1.4679 Test Acc: 0.4399\n",
      "Epoch:   35 Train Loss: 1.3246 Train Acc: 0.4707 Test Loss: 1.4708 Test Acc: 0.4024\n",
      "Epoch:   36 Train Loss: 1.2895 Train Acc: 0.4797 Test Loss: 1.4339 Test Acc: 0.4339\n",
      "Epoch:   37 Train Loss: 1.2639 Train Acc: 0.5034 Test Loss: 1.4348 Test Acc: 0.4489\n",
      "Epoch:   38 Train Loss: 1.2445 Train Acc: 0.5192 Test Loss: 1.4010 Test Acc: 0.4429\n",
      "Epoch:   39 Train Loss: 1.2128 Train Acc: 0.5331 Test Loss: 1.3695 Test Acc: 0.4700\n",
      "Epoch:   40 Train Loss: 1.1940 Train Acc: 0.5474 Test Loss: 1.3833 Test Acc: 0.4655\n",
      "Epoch:   41 Train Loss: 1.1915 Train Acc: 0.5406 Test Loss: 1.3766 Test Acc: 0.4880\n",
      "Epoch:   42 Train Loss: 1.1410 Train Acc: 0.5823 Test Loss: 1.3651 Test Acc: 0.4970\n",
      "Epoch:   43 Train Loss: 1.1305 Train Acc: 0.6038 Test Loss: 1.3528 Test Acc: 0.5075\n",
      "Epoch:   44 Train Loss: 1.1059 Train Acc: 0.6019 Test Loss: 1.3021 Test Acc: 0.5300\n",
      "Epoch:   45 Train Loss: 1.0752 Train Acc: 0.6222 Test Loss: 1.3009 Test Acc: 0.5135\n",
      "Epoch:   46 Train Loss: 1.0555 Train Acc: 0.6180 Test Loss: 1.3364 Test Acc: 0.5195\n",
      "Epoch:   47 Train Loss: 1.0252 Train Acc: 0.6429 Test Loss: 1.2602 Test Acc: 0.5375\n",
      "Epoch:   48 Train Loss: 1.0078 Train Acc: 0.6462 Test Loss: 1.2816 Test Acc: 0.5300\n",
      "Epoch:   49 Train Loss: 0.9744 Train Acc: 0.6722 Test Loss: 1.2623 Test Acc: 0.5631\n",
      "Epoch:   50 Train Loss: 0.9537 Train Acc: 0.6823 Test Loss: 1.2453 Test Acc: 0.5631\n",
      "Epoch:   51 Train Loss: 0.9332 Train Acc: 0.6801 Test Loss: 1.2090 Test Acc: 0.5751\n",
      "Epoch:   52 Train Loss: 0.9054 Train Acc: 0.6846 Test Loss: 1.2610 Test Acc: 0.5586\n",
      "Epoch:   53 Train Loss: 0.8919 Train Acc: 0.6906 Test Loss: 1.2621 Test Acc: 0.5841\n",
      "Epoch:   54 Train Loss: 0.8733 Train Acc: 0.6917 Test Loss: 1.2171 Test Acc: 0.5586\n",
      "Epoch:   55 Train Loss: 0.8570 Train Acc: 0.7038 Test Loss: 1.2290 Test Acc: 0.5721\n",
      "Epoch:   56 Train Loss: 0.8349 Train Acc: 0.7320 Test Loss: 1.2183 Test Acc: 0.5631\n",
      "Epoch:   57 Train Loss: 0.8184 Train Acc: 0.7162 Test Loss: 1.2088 Test Acc: 0.6096\n",
      "Epoch:   58 Train Loss: 0.7947 Train Acc: 0.7173 Test Loss: 1.2359 Test Acc: 0.5916\n",
      "Epoch:   59 Train Loss: 0.7592 Train Acc: 0.7432 Test Loss: 1.1684 Test Acc: 0.6171\n",
      "Epoch:   60 Train Loss: 0.7368 Train Acc: 0.7534 Test Loss: 1.1897 Test Acc: 0.6246\n",
      "Epoch:   61 Train Loss: 0.7230 Train Acc: 0.7553 Test Loss: 1.2064 Test Acc: 0.6141\n",
      "Epoch:   62 Train Loss: 0.7171 Train Acc: 0.7620 Test Loss: 1.1542 Test Acc: 0.6261\n",
      "Epoch:   63 Train Loss: 0.7043 Train Acc: 0.7523 Test Loss: 1.1860 Test Acc: 0.6246\n",
      "Epoch:   64 Train Loss: 0.6784 Train Acc: 0.7741 Test Loss: 1.1322 Test Acc: 0.6351\n",
      "Epoch:   65 Train Loss: 0.6536 Train Acc: 0.7789 Test Loss: 1.1243 Test Acc: 0.6517\n",
      "Epoch:   66 Train Loss: 0.6460 Train Acc: 0.7805 Test Loss: 1.1888 Test Acc: 0.6276\n",
      "Epoch:   67 Train Loss: 0.6339 Train Acc: 0.7793 Test Loss: 1.2397 Test Acc: 0.5991\n",
      "Epoch:   68 Train Loss: 0.6049 Train Acc: 0.7921 Test Loss: 1.2352 Test Acc: 0.6276\n",
      "Epoch:   69 Train Loss: 0.6042 Train Acc: 0.7917 Test Loss: 1.1721 Test Acc: 0.6441\n",
      "Epoch:   70 Train Loss: 0.5913 Train Acc: 0.7925 Test Loss: 1.1389 Test Acc: 0.6471\n",
      "Epoch:   71 Train Loss: 0.5674 Train Acc: 0.8109 Test Loss: 1.1094 Test Acc: 0.6532\n",
      "Epoch:   72 Train Loss: 0.5410 Train Acc: 0.8109 Test Loss: 1.1380 Test Acc: 0.6607\n",
      "Epoch:   73 Train Loss: 0.5565 Train Acc: 0.8158 Test Loss: 1.1447 Test Acc: 0.6366\n",
      "Epoch:   74 Train Loss: 0.5256 Train Acc: 0.8233 Test Loss: 1.1786 Test Acc: 0.6562\n",
      "Epoch:   75 Train Loss: 0.5216 Train Acc: 0.8143 Test Loss: 1.1880 Test Acc: 0.6562\n",
      "Epoch:   76 Train Loss: 0.4860 Train Acc: 0.8274 Test Loss: 1.1593 Test Acc: 0.6486\n",
      "Epoch:   77 Train Loss: 0.4848 Train Acc: 0.8361 Test Loss: 1.2133 Test Acc: 0.6667\n",
      "Epoch:   78 Train Loss: 0.4577 Train Acc: 0.8410 Test Loss: 1.2313 Test Acc: 0.6532\n",
      "Epoch:   79 Train Loss: 0.4536 Train Acc: 0.8383 Test Loss: 1.1461 Test Acc: 0.6727\n",
      "Epoch:   80 Train Loss: 0.4611 Train Acc: 0.8406 Test Loss: 1.2751 Test Acc: 0.6366\n",
      "Epoch:   81 Train Loss: 0.4268 Train Acc: 0.8511 Test Loss: 1.2249 Test Acc: 0.6547\n",
      "Epoch:   82 Train Loss: 0.4453 Train Acc: 0.8368 Test Loss: 1.2818 Test Acc: 0.6577\n",
      "Epoch:   83 Train Loss: 0.4230 Train Acc: 0.8466 Test Loss: 1.3094 Test Acc: 0.6426\n",
      "Epoch:   84 Train Loss: 0.3969 Train Acc: 0.8605 Test Loss: 1.2798 Test Acc: 0.6577\n",
      "Epoch:   85 Train Loss: 0.4163 Train Acc: 0.8492 Test Loss: 1.2286 Test Acc: 0.6562\n",
      "Epoch:   86 Train Loss: 0.3773 Train Acc: 0.8617 Test Loss: 1.3478 Test Acc: 0.6486\n",
      "Epoch:   87 Train Loss: 0.3848 Train Acc: 0.8617 Test Loss: 1.3394 Test Acc: 0.6772\n",
      "Epoch:   88 Train Loss: 0.3744 Train Acc: 0.8635 Test Loss: 1.2040 Test Acc: 0.6607\n",
      "Epoch:   89 Train Loss: 0.3511 Train Acc: 0.8726 Test Loss: 1.2188 Test Acc: 0.6712\n",
      "Epoch:   90 Train Loss: 0.3604 Train Acc: 0.8703 Test Loss: 1.3357 Test Acc: 0.6847\n",
      "Epoch:   91 Train Loss: 0.3438 Train Acc: 0.8741 Test Loss: 1.3297 Test Acc: 0.6727\n",
      "Epoch:   92 Train Loss: 0.3395 Train Acc: 0.8771 Test Loss: 1.3201 Test Acc: 0.6592\n",
      "Epoch:   93 Train Loss: 0.3173 Train Acc: 0.8857 Test Loss: 1.4192 Test Acc: 0.6517\n",
      "Epoch:   94 Train Loss: 0.3233 Train Acc: 0.8835 Test Loss: 1.3795 Test Acc: 0.6622\n",
      "Epoch:   95 Train Loss: 0.3163 Train Acc: 0.8808 Test Loss: 1.3121 Test Acc: 0.6817\n",
      "Epoch:   96 Train Loss: 0.2996 Train Acc: 0.8906 Test Loss: 1.4241 Test Acc: 0.6652\n",
      "Epoch:   97 Train Loss: 0.3096 Train Acc: 0.8801 Test Loss: 1.3067 Test Acc: 0.6772\n",
      "Epoch:   98 Train Loss: 0.2829 Train Acc: 0.8985 Test Loss: 1.3307 Test Acc: 0.6997\n",
      "Epoch:   99 Train Loss: 0.2891 Train Acc: 0.8940 Test Loss: 1.3747 Test Acc: 0.6652\n",
      "Epoch:  100 Train Loss: 0.2939 Train Acc: 0.8880 Test Loss: 1.4108 Test Acc: 0.6757\n",
      "Epoch:  101 Train Loss: 0.2742 Train Acc: 0.9071 Test Loss: 1.2625 Test Acc: 0.6952\n",
      "Epoch:  102 Train Loss: 0.2745 Train Acc: 0.9049 Test Loss: 1.4449 Test Acc: 0.6652\n",
      "Epoch:  103 Train Loss: 0.2625 Train Acc: 0.9056 Test Loss: 1.4442 Test Acc: 0.6757\n",
      "Epoch:  104 Train Loss: 0.2628 Train Acc: 0.9075 Test Loss: 1.4465 Test Acc: 0.6787\n",
      "Epoch:  105 Train Loss: 0.2433 Train Acc: 0.9150 Test Loss: 1.4950 Test Acc: 0.6877\n",
      "Epoch:  106 Train Loss: 0.2421 Train Acc: 0.9188 Test Loss: 1.5614 Test Acc: 0.7042\n",
      "Epoch:  107 Train Loss: 0.2351 Train Acc: 0.9207 Test Loss: 1.5307 Test Acc: 0.6877\n",
      "Epoch:  108 Train Loss: 0.2272 Train Acc: 0.9278 Test Loss: 1.5261 Test Acc: 0.6847\n",
      "Epoch:  109 Train Loss: 0.2388 Train Acc: 0.9169 Test Loss: 1.5589 Test Acc: 0.6787\n",
      "Epoch:  110 Train Loss: 0.2272 Train Acc: 0.9278 Test Loss: 1.4719 Test Acc: 0.6697\n",
      "Epoch:  111 Train Loss: 0.2293 Train Acc: 0.9256 Test Loss: 1.4898 Test Acc: 0.6787\n",
      "Epoch:  112 Train Loss: 0.2211 Train Acc: 0.9308 Test Loss: 1.4976 Test Acc: 0.6847\n",
      "Epoch:  113 Train Loss: 0.2185 Train Acc: 0.9305 Test Loss: 1.5862 Test Acc: 0.6802\n",
      "Epoch:  114 Train Loss: 0.2064 Train Acc: 0.9346 Test Loss: 1.5410 Test Acc: 0.6607\n",
      "Epoch:  115 Train Loss: 0.2098 Train Acc: 0.9338 Test Loss: 1.4005 Test Acc: 0.7207\n",
      "Epoch:  116 Train Loss: 0.1984 Train Acc: 0.9383 Test Loss: 1.4704 Test Acc: 0.6952\n",
      "Epoch:  117 Train Loss: 0.1922 Train Acc: 0.9402 Test Loss: 1.6169 Test Acc: 0.6907\n",
      "Epoch:  118 Train Loss: 0.1962 Train Acc: 0.9383 Test Loss: 1.4464 Test Acc: 0.6922\n",
      "Epoch:  119 Train Loss: 0.1831 Train Acc: 0.9466 Test Loss: 1.4825 Test Acc: 0.7012\n",
      "Epoch:  120 Train Loss: 0.1859 Train Acc: 0.9451 Test Loss: 1.6042 Test Acc: 0.6937\n",
      "Epoch:  121 Train Loss: 0.1874 Train Acc: 0.9477 Test Loss: 1.4887 Test Acc: 0.6922\n",
      "Epoch:  122 Train Loss: 0.1756 Train Acc: 0.9477 Test Loss: 1.5758 Test Acc: 0.6862\n",
      "Epoch:  123 Train Loss: 0.1689 Train Acc: 0.9508 Test Loss: 1.7130 Test Acc: 0.6637\n",
      "Epoch:  124 Train Loss: 0.1706 Train Acc: 0.9534 Test Loss: 1.6699 Test Acc: 0.6772\n",
      "Epoch:  125 Train Loss: 0.1674 Train Acc: 0.9492 Test Loss: 1.7180 Test Acc: 0.6907\n",
      "Epoch:  126 Train Loss: 0.1596 Train Acc: 0.9579 Test Loss: 1.8045 Test Acc: 0.6952\n",
      "Epoch:  127 Train Loss: 0.1584 Train Acc: 0.9586 Test Loss: 1.6655 Test Acc: 0.6772\n",
      "Epoch:  128 Train Loss: 0.1677 Train Acc: 0.9538 Test Loss: 1.5914 Test Acc: 0.6982\n",
      "Epoch:  129 Train Loss: 0.1565 Train Acc: 0.9579 Test Loss: 1.5120 Test Acc: 0.7027\n",
      "Epoch:  130 Train Loss: 0.1650 Train Acc: 0.9515 Test Loss: 1.5970 Test Acc: 0.6952\n",
      "Epoch:  131 Train Loss: 0.1563 Train Acc: 0.9602 Test Loss: 1.7191 Test Acc: 0.6862\n",
      "Epoch:  132 Train Loss: 0.1500 Train Acc: 0.9556 Test Loss: 1.8547 Test Acc: 0.6592\n",
      "Epoch:  133 Train Loss: 0.1548 Train Acc: 0.9575 Test Loss: 1.7733 Test Acc: 0.6847\n",
      "Epoch:  134 Train Loss: 0.1400 Train Acc: 0.9647 Test Loss: 1.7209 Test Acc: 0.6817\n",
      "Epoch:  135 Train Loss: 0.1407 Train Acc: 0.9628 Test Loss: 1.7680 Test Acc: 0.6907\n",
      "Epoch:  136 Train Loss: 0.1322 Train Acc: 0.9650 Test Loss: 1.8241 Test Acc: 0.6787\n",
      "Epoch:  137 Train Loss: 0.1357 Train Acc: 0.9643 Test Loss: 1.8399 Test Acc: 0.6847\n",
      "Epoch:  138 Train Loss: 0.1359 Train Acc: 0.9613 Test Loss: 1.7058 Test Acc: 0.6922\n",
      "Epoch:  139 Train Loss: 0.1247 Train Acc: 0.9711 Test Loss: 1.9034 Test Acc: 0.6877\n",
      "Epoch:  140 Train Loss: 0.1224 Train Acc: 0.9688 Test Loss: 1.7397 Test Acc: 0.6742\n",
      "Epoch:  141 Train Loss: 0.1272 Train Acc: 0.9662 Test Loss: 1.8482 Test Acc: 0.6997\n",
      "Epoch:  142 Train Loss: 0.1148 Train Acc: 0.9718 Test Loss: 1.8158 Test Acc: 0.6877\n",
      "Epoch:  143 Train Loss: 0.1332 Train Acc: 0.9665 Test Loss: 1.8998 Test Acc: 0.6892\n",
      "Epoch:  144 Train Loss: 0.1197 Train Acc: 0.9722 Test Loss: 1.8688 Test Acc: 0.6982\n",
      "Epoch:  145 Train Loss: 0.1117 Train Acc: 0.9722 Test Loss: 1.8694 Test Acc: 0.7012\n",
      "Epoch:  146 Train Loss: 0.1150 Train Acc: 0.9669 Test Loss: 1.7876 Test Acc: 0.6892\n",
      "Epoch:  147 Train Loss: 0.1125 Train Acc: 0.9711 Test Loss: 1.9061 Test Acc: 0.6997\n",
      "Epoch:  148 Train Loss: 0.1126 Train Acc: 0.9695 Test Loss: 2.0485 Test Acc: 0.6997\n",
      "Epoch:  149 Train Loss: 0.1091 Train Acc: 0.9744 Test Loss: 1.9976 Test Acc: 0.7027\n",
      "Epoch:  150 Train Loss: 0.1062 Train Acc: 0.9752 Test Loss: 1.9295 Test Acc: 0.6862\n",
      "Epoch:  151 Train Loss: 0.0966 Train Acc: 0.9793 Test Loss: 1.7093 Test Acc: 0.7087\n",
      "Epoch:  152 Train Loss: 0.1057 Train Acc: 0.9703 Test Loss: 1.9178 Test Acc: 0.7042\n",
      "Epoch:  153 Train Loss: 0.0951 Train Acc: 0.9786 Test Loss: 1.8627 Test Acc: 0.6817\n",
      "Epoch:  154 Train Loss: 0.0971 Train Acc: 0.9756 Test Loss: 1.7798 Test Acc: 0.7147\n",
      "Epoch:  155 Train Loss: 0.0927 Train Acc: 0.9771 Test Loss: 1.8672 Test Acc: 0.6892\n",
      "Epoch:  156 Train Loss: 0.0945 Train Acc: 0.9756 Test Loss: 2.0902 Test Acc: 0.6922\n",
      "Epoch:  157 Train Loss: 0.0984 Train Acc: 0.9789 Test Loss: 1.9781 Test Acc: 0.6922\n",
      "Epoch:  158 Train Loss: 0.0895 Train Acc: 0.9808 Test Loss: 1.8146 Test Acc: 0.7042\n",
      "Epoch:  159 Train Loss: 0.0995 Train Acc: 0.9744 Test Loss: 1.7900 Test Acc: 0.7087\n",
      "Epoch:  160 Train Loss: 0.0984 Train Acc: 0.9774 Test Loss: 2.0508 Test Acc: 0.7042\n",
      "Epoch:  161 Train Loss: 0.0994 Train Acc: 0.9756 Test Loss: 1.8725 Test Acc: 0.7117\n",
      "Epoch:  162 Train Loss: 0.0864 Train Acc: 0.9797 Test Loss: 1.8119 Test Acc: 0.6997\n",
      "Epoch:  163 Train Loss: 0.0851 Train Acc: 0.9820 Test Loss: 2.0882 Test Acc: 0.6817\n",
      "Epoch:  164 Train Loss: 0.0846 Train Acc: 0.9805 Test Loss: 2.0080 Test Acc: 0.7087\n",
      "Epoch:  165 Train Loss: 0.0792 Train Acc: 0.9838 Test Loss: 2.2682 Test Acc: 0.7057\n",
      "Epoch:  166 Train Loss: 0.0824 Train Acc: 0.9782 Test Loss: 1.9600 Test Acc: 0.7102\n",
      "Epoch:  167 Train Loss: 0.0873 Train Acc: 0.9782 Test Loss: 2.0032 Test Acc: 0.6952\n",
      "Epoch:  168 Train Loss: 0.0748 Train Acc: 0.9850 Test Loss: 1.8982 Test Acc: 0.7177\n",
      "Epoch:  169 Train Loss: 0.0750 Train Acc: 0.9842 Test Loss: 2.0395 Test Acc: 0.6877\n",
      "Epoch:  170 Train Loss: 0.0808 Train Acc: 0.9835 Test Loss: 2.0465 Test Acc: 0.6922\n",
      "Epoch:  171 Train Loss: 0.0827 Train Acc: 0.9774 Test Loss: 2.1053 Test Acc: 0.6877\n",
      "Epoch:  172 Train Loss: 0.0876 Train Acc: 0.9797 Test Loss: 2.0743 Test Acc: 0.7027\n",
      "Epoch:  173 Train Loss: 0.0843 Train Acc: 0.9793 Test Loss: 2.1407 Test Acc: 0.6997\n",
      "Epoch:  174 Train Loss: 0.0771 Train Acc: 0.9812 Test Loss: 2.2021 Test Acc: 0.7072\n",
      "Epoch:  175 Train Loss: 0.0810 Train Acc: 0.9763 Test Loss: 2.0596 Test Acc: 0.7042\n",
      "Epoch:  176 Train Loss: 0.0753 Train Acc: 0.9820 Test Loss: 2.0480 Test Acc: 0.6952\n",
      "Epoch:  177 Train Loss: 0.0801 Train Acc: 0.9835 Test Loss: 1.9504 Test Acc: 0.6907\n",
      "Epoch:  178 Train Loss: 0.0675 Train Acc: 0.9782 Test Loss: 2.1728 Test Acc: 0.6727\n",
      "Epoch:  179 Train Loss: 0.0852 Train Acc: 0.9756 Test Loss: 2.1205 Test Acc: 0.7117\n",
      "Epoch:  180 Train Loss: 0.0691 Train Acc: 0.9838 Test Loss: 2.1173 Test Acc: 0.7072\n",
      "Epoch:  181 Train Loss: 0.0805 Train Acc: 0.9793 Test Loss: 1.9711 Test Acc: 0.7072\n",
      "Epoch:  182 Train Loss: 0.0713 Train Acc: 0.9853 Test Loss: 2.1102 Test Acc: 0.7027\n",
      "Epoch:  183 Train Loss: 0.0646 Train Acc: 0.9823 Test Loss: 2.0278 Test Acc: 0.7027\n",
      "Epoch:  184 Train Loss: 0.0625 Train Acc: 0.9868 Test Loss: 2.0911 Test Acc: 0.6952\n",
      "Epoch:  185 Train Loss: 0.0714 Train Acc: 0.9820 Test Loss: 2.0726 Test Acc: 0.6982\n",
      "Epoch:  186 Train Loss: 0.0690 Train Acc: 0.9827 Test Loss: 2.0910 Test Acc: 0.7192\n",
      "Epoch:  187 Train Loss: 0.0647 Train Acc: 0.9842 Test Loss: 2.1077 Test Acc: 0.7117\n",
      "Epoch:  188 Train Loss: 0.0608 Train Acc: 0.9842 Test Loss: 2.2330 Test Acc: 0.6922\n",
      "Epoch:  189 Train Loss: 0.0710 Train Acc: 0.9812 Test Loss: 2.1110 Test Acc: 0.7177\n",
      "Epoch:  190 Train Loss: 0.0569 Train Acc: 0.9857 Test Loss: 2.2624 Test Acc: 0.6952\n",
      "Epoch:  191 Train Loss: 0.0561 Train Acc: 0.9898 Test Loss: 2.1574 Test Acc: 0.7237\n",
      "Epoch:  192 Train Loss: 0.0638 Train Acc: 0.9868 Test Loss: 1.9597 Test Acc: 0.7102\n",
      "Epoch:  193 Train Loss: 0.0613 Train Acc: 0.9823 Test Loss: 2.2528 Test Acc: 0.7012\n",
      "Epoch:  194 Train Loss: 0.0619 Train Acc: 0.9831 Test Loss: 2.2759 Test Acc: 0.7027\n",
      "Epoch:  195 Train Loss: 0.0607 Train Acc: 0.9850 Test Loss: 2.2050 Test Acc: 0.7027\n",
      "Epoch:  196 Train Loss: 0.0608 Train Acc: 0.9831 Test Loss: 2.1172 Test Acc: 0.7012\n",
      "Epoch:  197 Train Loss: 0.0598 Train Acc: 0.9883 Test Loss: 2.2073 Test Acc: 0.6982\n",
      "Epoch:  198 Train Loss: 0.0669 Train Acc: 0.9831 Test Loss: 2.1049 Test Acc: 0.7237\n",
      "Epoch:  199 Train Loss: 0.0616 Train Acc: 0.9838 Test Loss: 2.3680 Test Acc: 0.7042\n",
      "Epoch:  200 Train Loss: 0.0560 Train Acc: 0.9857 Test Loss: 2.2489 Test Acc: 0.7057\n",
      "Epoch:  201 Train Loss: 0.0548 Train Acc: 0.9880 Test Loss: 2.0193 Test Acc: 0.7087\n",
      "Epoch:  202 Train Loss: 0.0545 Train Acc: 0.9872 Test Loss: 2.4382 Test Acc: 0.6892\n",
      "Epoch:  203 Train Loss: 0.0590 Train Acc: 0.9857 Test Loss: 2.0848 Test Acc: 0.7087\n",
      "Epoch:  204 Train Loss: 0.0557 Train Acc: 0.9853 Test Loss: 2.2410 Test Acc: 0.7192\n",
      "Epoch:  205 Train Loss: 0.0573 Train Acc: 0.9846 Test Loss: 2.0861 Test Acc: 0.7087\n",
      "Epoch:  206 Train Loss: 0.0470 Train Acc: 0.9891 Test Loss: 2.1106 Test Acc: 0.7057\n",
      "Epoch:  207 Train Loss: 0.0551 Train Acc: 0.9895 Test Loss: 2.4100 Test Acc: 0.7027\n",
      "Epoch:  208 Train Loss: 0.0574 Train Acc: 0.9883 Test Loss: 2.1509 Test Acc: 0.7012\n",
      "Epoch:  209 Train Loss: 0.0518 Train Acc: 0.9865 Test Loss: 2.2206 Test Acc: 0.7057\n",
      "Epoch:  210 Train Loss: 0.0546 Train Acc: 0.9865 Test Loss: 2.0931 Test Acc: 0.7102\n",
      "Epoch:  211 Train Loss: 0.0558 Train Acc: 0.9853 Test Loss: 2.2909 Test Acc: 0.7102\n",
      "Epoch:  212 Train Loss: 0.0542 Train Acc: 0.9853 Test Loss: 2.2852 Test Acc: 0.7087\n",
      "Epoch:  213 Train Loss: 0.0569 Train Acc: 0.9872 Test Loss: 2.3717 Test Acc: 0.7057\n",
      "Epoch:  214 Train Loss: 0.0452 Train Acc: 0.9902 Test Loss: 2.2635 Test Acc: 0.6982\n",
      "Epoch:  215 Train Loss: 0.0523 Train Acc: 0.9872 Test Loss: 2.1757 Test Acc: 0.7072\n",
      "Epoch:  216 Train Loss: 0.0521 Train Acc: 0.9898 Test Loss: 2.2977 Test Acc: 0.6832\n",
      "Epoch:  217 Train Loss: 0.0527 Train Acc: 0.9861 Test Loss: 2.0890 Test Acc: 0.7117\n",
      "Epoch:  218 Train Loss: 0.0584 Train Acc: 0.9853 Test Loss: 2.2812 Test Acc: 0.7027\n",
      "Epoch:  219 Train Loss: 0.0541 Train Acc: 0.9872 Test Loss: 2.2730 Test Acc: 0.6922\n",
      "Epoch:  220 Train Loss: 0.0445 Train Acc: 0.9883 Test Loss: 2.2454 Test Acc: 0.7042\n",
      "Epoch:  221 Train Loss: 0.0463 Train Acc: 0.9883 Test Loss: 2.3858 Test Acc: 0.7132\n",
      "Epoch:  222 Train Loss: 0.0418 Train Acc: 0.9910 Test Loss: 2.2840 Test Acc: 0.7012\n",
      "Epoch:  223 Train Loss: 0.0474 Train Acc: 0.9887 Test Loss: 2.2818 Test Acc: 0.7177\n",
      "Epoch:  224 Train Loss: 0.0414 Train Acc: 0.9921 Test Loss: 2.3433 Test Acc: 0.7057\n",
      "Epoch:  225 Train Loss: 0.0451 Train Acc: 0.9880 Test Loss: 2.2629 Test Acc: 0.7132\n",
      "Epoch:  226 Train Loss: 0.0452 Train Acc: 0.9891 Test Loss: 2.4998 Test Acc: 0.6997\n",
      "Epoch:  227 Train Loss: 0.0468 Train Acc: 0.9891 Test Loss: 2.4052 Test Acc: 0.6937\n",
      "Epoch:  228 Train Loss: 0.0403 Train Acc: 0.9898 Test Loss: 2.5732 Test Acc: 0.6967\n",
      "Epoch:  229 Train Loss: 0.0441 Train Acc: 0.9872 Test Loss: 2.3305 Test Acc: 0.6982\n",
      "Epoch:  230 Train Loss: 0.0426 Train Acc: 0.9936 Test Loss: 2.4300 Test Acc: 0.7087\n",
      "Epoch:  231 Train Loss: 0.0453 Train Acc: 0.9902 Test Loss: 2.3719 Test Acc: 0.7012\n",
      "Epoch:  232 Train Loss: 0.0393 Train Acc: 0.9891 Test Loss: 2.3264 Test Acc: 0.6982\n",
      "Epoch:  233 Train Loss: 0.0378 Train Acc: 0.9917 Test Loss: 2.5257 Test Acc: 0.7087\n",
      "Epoch:  234 Train Loss: 0.0435 Train Acc: 0.9872 Test Loss: 2.4264 Test Acc: 0.7177\n",
      "Epoch:  235 Train Loss: 0.0429 Train Acc: 0.9910 Test Loss: 2.5831 Test Acc: 0.6952\n",
      "Epoch:  236 Train Loss: 0.0414 Train Acc: 0.9868 Test Loss: 2.4243 Test Acc: 0.6982\n",
      "Epoch:  237 Train Loss: 0.0477 Train Acc: 0.9865 Test Loss: 2.3370 Test Acc: 0.7192\n",
      "Epoch:  238 Train Loss: 0.0426 Train Acc: 0.9910 Test Loss: 2.3429 Test Acc: 0.7117\n",
      "Epoch:  239 Train Loss: 0.0416 Train Acc: 0.9883 Test Loss: 2.3022 Test Acc: 0.7102\n",
      "Epoch:  240 Train Loss: 0.0437 Train Acc: 0.9887 Test Loss: 2.3562 Test Acc: 0.7087\n",
      "Epoch:  241 Train Loss: 0.0453 Train Acc: 0.9917 Test Loss: 2.5513 Test Acc: 0.7012\n",
      "Epoch:  242 Train Loss: 0.0409 Train Acc: 0.9902 Test Loss: 2.3336 Test Acc: 0.6952\n",
      "Epoch:  243 Train Loss: 0.0432 Train Acc: 0.9880 Test Loss: 2.2826 Test Acc: 0.7327\n",
      "Epoch:  244 Train Loss: 0.0470 Train Acc: 0.9906 Test Loss: 2.5234 Test Acc: 0.7087\n",
      "Epoch:  245 Train Loss: 0.0455 Train Acc: 0.9895 Test Loss: 2.5011 Test Acc: 0.6847\n",
      "Epoch:  246 Train Loss: 0.0384 Train Acc: 0.9902 Test Loss: 2.5925 Test Acc: 0.6922\n",
      "Epoch:  247 Train Loss: 0.0492 Train Acc: 0.9861 Test Loss: 2.4421 Test Acc: 0.7207\n",
      "Epoch:  248 Train Loss: 0.0368 Train Acc: 0.9910 Test Loss: 2.3128 Test Acc: 0.6967\n",
      "Epoch:  249 Train Loss: 0.0384 Train Acc: 0.9917 Test Loss: 2.3046 Test Acc: 0.7042\n",
      "Epoch:  250 Train Loss: 0.0425 Train Acc: 0.9891 Test Loss: 2.2205 Test Acc: 0.7252\n",
      "Epoch:  251 Train Loss: 0.0457 Train Acc: 0.9883 Test Loss: 2.2916 Test Acc: 0.7102\n",
      "Epoch:  252 Train Loss: 0.0318 Train Acc: 0.9932 Test Loss: 2.5551 Test Acc: 0.7027\n",
      "Epoch:  253 Train Loss: 0.0349 Train Acc: 0.9914 Test Loss: 2.3859 Test Acc: 0.7252\n",
      "Epoch:  254 Train Loss: 0.0416 Train Acc: 0.9876 Test Loss: 2.4179 Test Acc: 0.7042\n",
      "Epoch:  255 Train Loss: 0.0426 Train Acc: 0.9891 Test Loss: 2.2305 Test Acc: 0.7252\n",
      "Epoch:  256 Train Loss: 0.0386 Train Acc: 0.9917 Test Loss: 2.4404 Test Acc: 0.6967\n",
      "Epoch:  257 Train Loss: 0.0388 Train Acc: 0.9925 Test Loss: 2.3212 Test Acc: 0.7237\n",
      "Epoch:  258 Train Loss: 0.0374 Train Acc: 0.9898 Test Loss: 2.4118 Test Acc: 0.7057\n",
      "Epoch:  259 Train Loss: 0.0357 Train Acc: 0.9898 Test Loss: 2.4973 Test Acc: 0.7102\n",
      "Epoch:  260 Train Loss: 0.0369 Train Acc: 0.9902 Test Loss: 2.4286 Test Acc: 0.7102\n",
      "Epoch:  261 Train Loss: 0.0457 Train Acc: 0.9872 Test Loss: 2.3917 Test Acc: 0.7012\n",
      "Epoch:  262 Train Loss: 0.0423 Train Acc: 0.9906 Test Loss: 2.3025 Test Acc: 0.7207\n",
      "Epoch:  263 Train Loss: 0.0419 Train Acc: 0.9902 Test Loss: 2.4233 Test Acc: 0.6892\n",
      "Epoch:  264 Train Loss: 0.0356 Train Acc: 0.9906 Test Loss: 2.3774 Test Acc: 0.7147\n",
      "Epoch:  265 Train Loss: 0.0341 Train Acc: 0.9902 Test Loss: 2.4203 Test Acc: 0.7012\n",
      "Epoch:  266 Train Loss: 0.0353 Train Acc: 0.9891 Test Loss: 2.7140 Test Acc: 0.6952\n",
      "Epoch:  267 Train Loss: 0.0362 Train Acc: 0.9917 Test Loss: 2.6366 Test Acc: 0.7087\n",
      "Epoch:  268 Train Loss: 0.0451 Train Acc: 0.9850 Test Loss: 2.3799 Test Acc: 0.7147\n",
      "Epoch:  269 Train Loss: 0.0349 Train Acc: 0.9925 Test Loss: 2.5511 Test Acc: 0.6967\n",
      "Epoch:  270 Train Loss: 0.0298 Train Acc: 0.9921 Test Loss: 2.6405 Test Acc: 0.7147\n",
      "Epoch:  271 Train Loss: 0.0413 Train Acc: 0.9891 Test Loss: 2.2934 Test Acc: 0.7087\n",
      "Epoch:  272 Train Loss: 0.0334 Train Acc: 0.9951 Test Loss: 2.2644 Test Acc: 0.7057\n",
      "Epoch:  273 Train Loss: 0.0332 Train Acc: 0.9925 Test Loss: 2.5415 Test Acc: 0.7042\n",
      "Epoch:  274 Train Loss: 0.0312 Train Acc: 0.9925 Test Loss: 2.5730 Test Acc: 0.7042\n",
      "Epoch:  275 Train Loss: 0.0348 Train Acc: 0.9914 Test Loss: 2.5565 Test Acc: 0.7102\n",
      "Epoch:  276 Train Loss: 0.0383 Train Acc: 0.9895 Test Loss: 2.4862 Test Acc: 0.7147\n",
      "Epoch:  277 Train Loss: 0.0361 Train Acc: 0.9917 Test Loss: 2.3110 Test Acc: 0.7057\n",
      "Epoch:  278 Train Loss: 0.0283 Train Acc: 0.9925 Test Loss: 2.6460 Test Acc: 0.7027\n",
      "Epoch:  279 Train Loss: 0.0270 Train Acc: 0.9947 Test Loss: 2.4808 Test Acc: 0.7072\n",
      "Epoch:  280 Train Loss: 0.0340 Train Acc: 0.9891 Test Loss: 2.6940 Test Acc: 0.7117\n",
      "Epoch:  281 Train Loss: 0.0305 Train Acc: 0.9921 Test Loss: 2.4934 Test Acc: 0.7132\n",
      "Epoch:  282 Train Loss: 0.0356 Train Acc: 0.9891 Test Loss: 2.4282 Test Acc: 0.7042\n",
      "Epoch:  283 Train Loss: 0.0309 Train Acc: 0.9936 Test Loss: 2.6710 Test Acc: 0.6967\n",
      "Epoch:  284 Train Loss: 0.0315 Train Acc: 0.9929 Test Loss: 2.5206 Test Acc: 0.7162\n",
      "Epoch:  285 Train Loss: 0.0273 Train Acc: 0.9940 Test Loss: 2.3445 Test Acc: 0.7132\n",
      "Epoch:  286 Train Loss: 0.0327 Train Acc: 0.9914 Test Loss: 2.6281 Test Acc: 0.7087\n",
      "Epoch:  287 Train Loss: 0.0326 Train Acc: 0.9936 Test Loss: 2.6639 Test Acc: 0.7087\n",
      "Epoch:  288 Train Loss: 0.0283 Train Acc: 0.9936 Test Loss: 2.5669 Test Acc: 0.7102\n",
      "Epoch:  289 Train Loss: 0.0271 Train Acc: 0.9944 Test Loss: 2.5526 Test Acc: 0.7222\n",
      "Epoch:  290 Train Loss: 0.0321 Train Acc: 0.9940 Test Loss: 2.5859 Test Acc: 0.7072\n",
      "Epoch:  291 Train Loss: 0.0368 Train Acc: 0.9917 Test Loss: 2.6244 Test Acc: 0.7162\n",
      "Epoch:  292 Train Loss: 0.0289 Train Acc: 0.9951 Test Loss: 2.5975 Test Acc: 0.7057\n",
      "Epoch:  293 Train Loss: 0.0305 Train Acc: 0.9925 Test Loss: 2.5567 Test Acc: 0.6982\n",
      "Epoch:  294 Train Loss: 0.0332 Train Acc: 0.9925 Test Loss: 2.4947 Test Acc: 0.7342\n",
      "Epoch:  295 Train Loss: 0.0237 Train Acc: 0.9955 Test Loss: 2.5537 Test Acc: 0.7102\n",
      "Epoch:  296 Train Loss: 0.0274 Train Acc: 0.9951 Test Loss: 2.3958 Test Acc: 0.7057\n",
      "Epoch:  297 Train Loss: 0.0293 Train Acc: 0.9936 Test Loss: 2.6007 Test Acc: 0.7132\n",
      "Epoch:  298 Train Loss: 0.0303 Train Acc: 0.9944 Test Loss: 2.9831 Test Acc: 0.6892\n",
      "Epoch:  299 Train Loss: 0.0238 Train Acc: 0.9947 Test Loss: 2.5251 Test Acc: 0.7207\n",
      "Epoch:  300 Train Loss: 0.0290 Train Acc: 0.9917 Test Loss: 2.5834 Test Acc: 0.7012\n",
      "Epoch:  301 Train Loss: 0.0311 Train Acc: 0.9929 Test Loss: 2.5918 Test Acc: 0.7327\n",
      "Epoch:  302 Train Loss: 0.0310 Train Acc: 0.9921 Test Loss: 2.4018 Test Acc: 0.6997\n",
      "Epoch:  303 Train Loss: 0.0329 Train Acc: 0.9910 Test Loss: 2.6928 Test Acc: 0.7027\n",
      "Epoch:  304 Train Loss: 0.0308 Train Acc: 0.9917 Test Loss: 2.7892 Test Acc: 0.6952\n",
      "Epoch:  305 Train Loss: 0.0286 Train Acc: 0.9940 Test Loss: 2.6857 Test Acc: 0.7267\n",
      "Epoch:  306 Train Loss: 0.0344 Train Acc: 0.9906 Test Loss: 2.7313 Test Acc: 0.7072\n",
      "Epoch:  307 Train Loss: 0.0371 Train Acc: 0.9914 Test Loss: 2.5644 Test Acc: 0.7132\n",
      "Epoch:  308 Train Loss: 0.0259 Train Acc: 0.9925 Test Loss: 2.6287 Test Acc: 0.7207\n",
      "Epoch:  309 Train Loss: 0.0334 Train Acc: 0.9925 Test Loss: 2.6631 Test Acc: 0.7042\n",
      "Epoch:  310 Train Loss: 0.0260 Train Acc: 0.9936 Test Loss: 2.6618 Test Acc: 0.6952\n",
      "Epoch:  311 Train Loss: 0.0285 Train Acc: 0.9910 Test Loss: 2.3195 Test Acc: 0.7222\n",
      "Epoch:  312 Train Loss: 0.0251 Train Acc: 0.9936 Test Loss: 2.4884 Test Acc: 0.7237\n",
      "Epoch:  313 Train Loss: 0.0275 Train Acc: 0.9925 Test Loss: 2.6951 Test Acc: 0.6967\n",
      "Epoch:  314 Train Loss: 0.0292 Train Acc: 0.9914 Test Loss: 2.4354 Test Acc: 0.7027\n",
      "Epoch:  315 Train Loss: 0.0234 Train Acc: 0.9940 Test Loss: 2.6937 Test Acc: 0.7057\n",
      "Epoch:  316 Train Loss: 0.0302 Train Acc: 0.9929 Test Loss: 2.6531 Test Acc: 0.7072\n",
      "Epoch:  317 Train Loss: 0.0245 Train Acc: 0.9947 Test Loss: 2.6222 Test Acc: 0.6997\n",
      "Epoch:  318 Train Loss: 0.0323 Train Acc: 0.9906 Test Loss: 2.6947 Test Acc: 0.6997\n",
      "Epoch:  319 Train Loss: 0.0304 Train Acc: 0.9944 Test Loss: 2.7868 Test Acc: 0.7087\n",
      "Epoch:  320 Train Loss: 0.0293 Train Acc: 0.9925 Test Loss: 2.8263 Test Acc: 0.7117\n",
      "Epoch:  321 Train Loss: 0.0208 Train Acc: 0.9959 Test Loss: 2.6822 Test Acc: 0.7162\n",
      "Epoch:  322 Train Loss: 0.0289 Train Acc: 0.9914 Test Loss: 2.5940 Test Acc: 0.7012\n",
      "Epoch:  323 Train Loss: 0.0275 Train Acc: 0.9944 Test Loss: 2.5378 Test Acc: 0.7027\n",
      "Epoch:  324 Train Loss: 0.0258 Train Acc: 0.9944 Test Loss: 2.8778 Test Acc: 0.7222\n",
      "Epoch:  325 Train Loss: 0.0282 Train Acc: 0.9917 Test Loss: 2.6511 Test Acc: 0.7192\n",
      "Epoch:  326 Train Loss: 0.0297 Train Acc: 0.9936 Test Loss: 2.8652 Test Acc: 0.7042\n",
      "Epoch:  327 Train Loss: 0.0285 Train Acc: 0.9925 Test Loss: 3.0148 Test Acc: 0.7147\n",
      "Epoch:  328 Train Loss: 0.0358 Train Acc: 0.9891 Test Loss: 2.6443 Test Acc: 0.6982\n",
      "Epoch:  329 Train Loss: 0.0238 Train Acc: 0.9932 Test Loss: 2.8986 Test Acc: 0.6802\n",
      "Epoch:  330 Train Loss: 0.0240 Train Acc: 0.9959 Test Loss: 2.6549 Test Acc: 0.7117\n",
      "Epoch:  331 Train Loss: 0.0164 Train Acc: 0.9974 Test Loss: 2.8021 Test Acc: 0.7027\n",
      "Epoch:  332 Train Loss: 0.0325 Train Acc: 0.9910 Test Loss: 2.8178 Test Acc: 0.7042\n",
      "Epoch:  333 Train Loss: 0.0291 Train Acc: 0.9921 Test Loss: 2.9632 Test Acc: 0.7147\n",
      "Epoch:  334 Train Loss: 0.0272 Train Acc: 0.9932 Test Loss: 2.6822 Test Acc: 0.7087\n",
      "Epoch:  335 Train Loss: 0.0232 Train Acc: 0.9932 Test Loss: 2.7494 Test Acc: 0.6982\n",
      "Epoch:  336 Train Loss: 0.0210 Train Acc: 0.9959 Test Loss: 2.6649 Test Acc: 0.7042\n",
      "Epoch:  337 Train Loss: 0.0242 Train Acc: 0.9955 Test Loss: 2.7722 Test Acc: 0.7117\n",
      "Epoch:  338 Train Loss: 0.0254 Train Acc: 0.9936 Test Loss: 2.7020 Test Acc: 0.6847\n",
      "Epoch:  339 Train Loss: 0.0269 Train Acc: 0.9921 Test Loss: 2.5915 Test Acc: 0.7222\n",
      "Epoch:  340 Train Loss: 0.0268 Train Acc: 0.9947 Test Loss: 2.4279 Test Acc: 0.7072\n",
      "Epoch:  341 Train Loss: 0.0256 Train Acc: 0.9932 Test Loss: 2.5513 Test Acc: 0.7147\n",
      "Epoch:  342 Train Loss: 0.0212 Train Acc: 0.9940 Test Loss: 2.9882 Test Acc: 0.7012\n",
      "Epoch:  343 Train Loss: 0.0238 Train Acc: 0.9955 Test Loss: 2.5883 Test Acc: 0.7162\n",
      "Epoch:  344 Train Loss: 0.0261 Train Acc: 0.9944 Test Loss: 2.8604 Test Acc: 0.7297\n",
      "Epoch:  345 Train Loss: 0.0248 Train Acc: 0.9936 Test Loss: 2.7218 Test Acc: 0.7267\n",
      "Epoch:  346 Train Loss: 0.0224 Train Acc: 0.9947 Test Loss: 2.9295 Test Acc: 0.7147\n",
      "Epoch:  347 Train Loss: 0.0208 Train Acc: 0.9955 Test Loss: 2.8052 Test Acc: 0.7102\n",
      "Epoch:  348 Train Loss: 0.0259 Train Acc: 0.9940 Test Loss: 2.4555 Test Acc: 0.7087\n",
      "Epoch:  349 Train Loss: 0.0273 Train Acc: 0.9940 Test Loss: 2.7529 Test Acc: 0.7027\n",
      "Epoch:  350 Train Loss: 0.0219 Train Acc: 0.9951 Test Loss: 2.7193 Test Acc: 0.7117\n",
      "Epoch:  351 Train Loss: 0.0237 Train Acc: 0.9936 Test Loss: 2.5640 Test Acc: 0.7222\n",
      "Epoch:  352 Train Loss: 0.0270 Train Acc: 0.9929 Test Loss: 3.2219 Test Acc: 0.6937\n",
      "Epoch:  353 Train Loss: 0.0195 Train Acc: 0.9966 Test Loss: 2.8752 Test Acc: 0.7012\n",
      "Epoch:  354 Train Loss: 0.0240 Train Acc: 0.9944 Test Loss: 2.8761 Test Acc: 0.6997\n",
      "Epoch:  355 Train Loss: 0.0260 Train Acc: 0.9921 Test Loss: 2.9119 Test Acc: 0.7177\n",
      "Epoch:  356 Train Loss: 0.0216 Train Acc: 0.9955 Test Loss: 2.8398 Test Acc: 0.7192\n",
      "Epoch:  357 Train Loss: 0.0244 Train Acc: 0.9940 Test Loss: 2.7940 Test Acc: 0.7117\n",
      "Epoch:  358 Train Loss: 0.0188 Train Acc: 0.9959 Test Loss: 2.7930 Test Acc: 0.7147\n",
      "Epoch:  359 Train Loss: 0.0218 Train Acc: 0.9936 Test Loss: 2.8372 Test Acc: 0.7297\n",
      "Epoch:  360 Train Loss: 0.0217 Train Acc: 0.9962 Test Loss: 2.9775 Test Acc: 0.7267\n",
      "Epoch:  361 Train Loss: 0.0207 Train Acc: 0.9947 Test Loss: 2.9097 Test Acc: 0.7102\n",
      "Epoch:  362 Train Loss: 0.0239 Train Acc: 0.9947 Test Loss: 3.2407 Test Acc: 0.7027\n",
      "Epoch:  363 Train Loss: 0.0252 Train Acc: 0.9917 Test Loss: 2.5397 Test Acc: 0.7177\n",
      "Epoch:  364 Train Loss: 0.0202 Train Acc: 0.9947 Test Loss: 2.6745 Test Acc: 0.7072\n",
      "Epoch:  365 Train Loss: 0.0216 Train Acc: 0.9940 Test Loss: 2.9474 Test Acc: 0.7117\n",
      "Epoch:  366 Train Loss: 0.0215 Train Acc: 0.9947 Test Loss: 2.7368 Test Acc: 0.7072\n",
      "Epoch:  367 Train Loss: 0.0262 Train Acc: 0.9921 Test Loss: 3.0141 Test Acc: 0.7012\n",
      "Epoch:  368 Train Loss: 0.0318 Train Acc: 0.9944 Test Loss: 2.8532 Test Acc: 0.7192\n",
      "Epoch:  369 Train Loss: 0.0271 Train Acc: 0.9936 Test Loss: 3.1149 Test Acc: 0.7027\n",
      "Epoch:  370 Train Loss: 0.0181 Train Acc: 0.9959 Test Loss: 2.8872 Test Acc: 0.7162\n",
      "Epoch:  371 Train Loss: 0.0210 Train Acc: 0.9955 Test Loss: 2.9518 Test Acc: 0.7132\n",
      "Epoch:  372 Train Loss: 0.0222 Train Acc: 0.9944 Test Loss: 2.7205 Test Acc: 0.7072\n",
      "Epoch:  373 Train Loss: 0.0209 Train Acc: 0.9947 Test Loss: 2.7858 Test Acc: 0.7087\n",
      "Epoch:  374 Train Loss: 0.0158 Train Acc: 0.9951 Test Loss: 2.7138 Test Acc: 0.7057\n",
      "Epoch:  375 Train Loss: 0.0254 Train Acc: 0.9921 Test Loss: 3.0071 Test Acc: 0.7267\n",
      "Epoch:  376 Train Loss: 0.0231 Train Acc: 0.9925 Test Loss: 3.0565 Test Acc: 0.7072\n",
      "Epoch:  377 Train Loss: 0.0263 Train Acc: 0.9929 Test Loss: 2.7103 Test Acc: 0.7012\n",
      "Epoch:  378 Train Loss: 0.0215 Train Acc: 0.9940 Test Loss: 2.7385 Test Acc: 0.7207\n",
      "Epoch:  379 Train Loss: 0.0164 Train Acc: 0.9970 Test Loss: 3.0058 Test Acc: 0.6937\n",
      "Epoch:  380 Train Loss: 0.0226 Train Acc: 0.9936 Test Loss: 2.8250 Test Acc: 0.7222\n",
      "Epoch:  381 Train Loss: 0.0182 Train Acc: 0.9955 Test Loss: 2.6235 Test Acc: 0.6997\n",
      "Epoch:  382 Train Loss: 0.0207 Train Acc: 0.9955 Test Loss: 2.8721 Test Acc: 0.7132\n",
      "Epoch:  383 Train Loss: 0.0208 Train Acc: 0.9959 Test Loss: 2.8902 Test Acc: 0.7132\n",
      "Epoch:  384 Train Loss: 0.0226 Train Acc: 0.9955 Test Loss: 2.8628 Test Acc: 0.7072\n",
      "Epoch:  385 Train Loss: 0.0186 Train Acc: 0.9955 Test Loss: 2.7270 Test Acc: 0.7267\n",
      "Epoch:  386 Train Loss: 0.0156 Train Acc: 0.9966 Test Loss: 2.8691 Test Acc: 0.7102\n",
      "Epoch:  387 Train Loss: 0.0204 Train Acc: 0.9951 Test Loss: 2.8583 Test Acc: 0.7102\n",
      "Epoch:  388 Train Loss: 0.0261 Train Acc: 0.9932 Test Loss: 3.0481 Test Acc: 0.6907\n",
      "Epoch:  389 Train Loss: 0.0272 Train Acc: 0.9936 Test Loss: 2.6852 Test Acc: 0.7117\n",
      "Epoch:  390 Train Loss: 0.0265 Train Acc: 0.9925 Test Loss: 3.0195 Test Acc: 0.6952\n",
      "Epoch:  391 Train Loss: 0.0189 Train Acc: 0.9974 Test Loss: 3.0105 Test Acc: 0.7132\n",
      "Epoch:  392 Train Loss: 0.0228 Train Acc: 0.9932 Test Loss: 2.7482 Test Acc: 0.7192\n",
      "Epoch:  393 Train Loss: 0.0234 Train Acc: 0.9929 Test Loss: 2.6399 Test Acc: 0.7117\n",
      "Epoch:  394 Train Loss: 0.0171 Train Acc: 0.9970 Test Loss: 2.8304 Test Acc: 0.7042\n",
      "Epoch:  395 Train Loss: 0.0152 Train Acc: 0.9974 Test Loss: 2.6909 Test Acc: 0.7177\n",
      "Epoch:  396 Train Loss: 0.0171 Train Acc: 0.9970 Test Loss: 2.7278 Test Acc: 0.7042\n",
      "Epoch:  397 Train Loss: 0.0186 Train Acc: 0.9951 Test Loss: 3.0899 Test Acc: 0.7012\n",
      "Epoch:  398 Train Loss: 0.0200 Train Acc: 0.9955 Test Loss: 2.8932 Test Acc: 0.7102\n",
      "Epoch:  399 Train Loss: 0.0310 Train Acc: 0.9921 Test Loss: 2.7309 Test Acc: 0.7072\n",
      "Epoch:  400 Train Loss: 0.0197 Train Acc: 0.9959 Test Loss: 2.9020 Test Acc: 0.7102\n",
      "Epoch:  401 Train Loss: 0.0210 Train Acc: 0.9947 Test Loss: 2.9928 Test Acc: 0.7177\n",
      "Epoch:  402 Train Loss: 0.0205 Train Acc: 0.9947 Test Loss: 3.0054 Test Acc: 0.7042\n",
      "Epoch:  403 Train Loss: 0.0214 Train Acc: 0.9955 Test Loss: 2.8064 Test Acc: 0.7342\n",
      "Epoch:  404 Train Loss: 0.0194 Train Acc: 0.9959 Test Loss: 2.8587 Test Acc: 0.7207\n",
      "Epoch:  405 Train Loss: 0.0216 Train Acc: 0.9944 Test Loss: 2.7641 Test Acc: 0.7072\n",
      "Epoch:  406 Train Loss: 0.0239 Train Acc: 0.9947 Test Loss: 2.6440 Test Acc: 0.7192\n",
      "Epoch:  407 Train Loss: 0.0275 Train Acc: 0.9936 Test Loss: 2.9541 Test Acc: 0.7012\n",
      "Epoch:  408 Train Loss: 0.0196 Train Acc: 0.9940 Test Loss: 2.7916 Test Acc: 0.7132\n",
      "Epoch:  409 Train Loss: 0.0191 Train Acc: 0.9962 Test Loss: 2.9256 Test Acc: 0.7162\n",
      "Epoch:  410 Train Loss: 0.0198 Train Acc: 0.9951 Test Loss: 3.0025 Test Acc: 0.7162\n",
      "Epoch:  411 Train Loss: 0.0181 Train Acc: 0.9947 Test Loss: 2.9715 Test Acc: 0.7162\n",
      "Epoch:  412 Train Loss: 0.0206 Train Acc: 0.9944 Test Loss: 2.6211 Test Acc: 0.7177\n",
      "Epoch:  413 Train Loss: 0.0171 Train Acc: 0.9966 Test Loss: 2.9781 Test Acc: 0.7027\n",
      "Epoch:  414 Train Loss: 0.0207 Train Acc: 0.9940 Test Loss: 2.8041 Test Acc: 0.7147\n",
      "Epoch:  415 Train Loss: 0.0232 Train Acc: 0.9955 Test Loss: 3.0121 Test Acc: 0.7147\n",
      "Epoch:  416 Train Loss: 0.0184 Train Acc: 0.9955 Test Loss: 3.1450 Test Acc: 0.7087\n",
      "Epoch:  417 Train Loss: 0.0240 Train Acc: 0.9962 Test Loss: 2.9633 Test Acc: 0.6907\n",
      "Epoch:  418 Train Loss: 0.0195 Train Acc: 0.9959 Test Loss: 3.0759 Test Acc: 0.6952\n",
      "Epoch:  419 Train Loss: 0.0172 Train Acc: 0.9955 Test Loss: 3.0032 Test Acc: 0.7237\n",
      "Epoch:  420 Train Loss: 0.0184 Train Acc: 0.9951 Test Loss: 2.8098 Test Acc: 0.7252\n",
      "Epoch:  421 Train Loss: 0.0201 Train Acc: 0.9951 Test Loss: 2.9743 Test Acc: 0.6982\n",
      "Epoch:  422 Train Loss: 0.0232 Train Acc: 0.9929 Test Loss: 3.1561 Test Acc: 0.7102\n",
      "Epoch:  423 Train Loss: 0.0175 Train Acc: 0.9951 Test Loss: 3.0809 Test Acc: 0.7027\n",
      "Epoch:  424 Train Loss: 0.0166 Train Acc: 0.9962 Test Loss: 2.8443 Test Acc: 0.7012\n",
      "Epoch:  425 Train Loss: 0.0149 Train Acc: 0.9970 Test Loss: 3.0618 Test Acc: 0.7117\n",
      "Epoch:  426 Train Loss: 0.0246 Train Acc: 0.9906 Test Loss: 2.9400 Test Acc: 0.7162\n",
      "Epoch:  427 Train Loss: 0.0193 Train Acc: 0.9955 Test Loss: 3.2096 Test Acc: 0.6997\n",
      "Epoch:  428 Train Loss: 0.0194 Train Acc: 0.9959 Test Loss: 3.0268 Test Acc: 0.7042\n",
      "Epoch:  429 Train Loss: 0.0189 Train Acc: 0.9951 Test Loss: 3.0089 Test Acc: 0.7057\n",
      "Epoch:  430 Train Loss: 0.0178 Train Acc: 0.9951 Test Loss: 2.8518 Test Acc: 0.7072\n",
      "Epoch:  431 Train Loss: 0.0159 Train Acc: 0.9962 Test Loss: 2.9669 Test Acc: 0.7012\n",
      "Epoch:  432 Train Loss: 0.0207 Train Acc: 0.9947 Test Loss: 3.0966 Test Acc: 0.7042\n",
      "Epoch:  433 Train Loss: 0.0193 Train Acc: 0.9951 Test Loss: 2.9555 Test Acc: 0.7132\n",
      "Epoch:  434 Train Loss: 0.0183 Train Acc: 0.9940 Test Loss: 3.1816 Test Acc: 0.6982\n",
      "Epoch:  435 Train Loss: 0.0194 Train Acc: 0.9962 Test Loss: 3.1830 Test Acc: 0.7012\n",
      "Epoch:  436 Train Loss: 0.0134 Train Acc: 0.9970 Test Loss: 2.8872 Test Acc: 0.7147\n",
      "Epoch:  437 Train Loss: 0.0164 Train Acc: 0.9951 Test Loss: 2.7435 Test Acc: 0.7072\n",
      "Epoch:  438 Train Loss: 0.0166 Train Acc: 0.9951 Test Loss: 2.8397 Test Acc: 0.7042\n",
      "Epoch:  439 Train Loss: 0.0140 Train Acc: 0.9977 Test Loss: 2.9928 Test Acc: 0.7222\n",
      "Epoch:  440 Train Loss: 0.0218 Train Acc: 0.9940 Test Loss: 3.0743 Test Acc: 0.7072\n",
      "Epoch:  441 Train Loss: 0.0140 Train Acc: 0.9970 Test Loss: 2.8580 Test Acc: 0.7222\n",
      "Epoch:  442 Train Loss: 0.0177 Train Acc: 0.9951 Test Loss: 3.2570 Test Acc: 0.7087\n",
      "Epoch:  443 Train Loss: 0.0195 Train Acc: 0.9940 Test Loss: 3.0651 Test Acc: 0.7237\n",
      "Epoch:  444 Train Loss: 0.0185 Train Acc: 0.9955 Test Loss: 3.0678 Test Acc: 0.6892\n",
      "Epoch:  445 Train Loss: 0.0160 Train Acc: 0.9962 Test Loss: 2.7698 Test Acc: 0.7222\n",
      "Epoch:  446 Train Loss: 0.0221 Train Acc: 0.9955 Test Loss: 3.2239 Test Acc: 0.7162\n",
      "Epoch:  447 Train Loss: 0.0248 Train Acc: 0.9921 Test Loss: 3.3389 Test Acc: 0.7057\n",
      "Epoch:  448 Train Loss: 0.0151 Train Acc: 0.9962 Test Loss: 3.0620 Test Acc: 0.7027\n",
      "Epoch:  449 Train Loss: 0.0161 Train Acc: 0.9970 Test Loss: 3.1987 Test Acc: 0.6997\n",
      "Epoch:  450 Train Loss: 0.0208 Train Acc: 0.9962 Test Loss: 2.9216 Test Acc: 0.7147\n",
      "Epoch:  451 Train Loss: 0.0146 Train Acc: 0.9959 Test Loss: 2.9979 Test Acc: 0.7102\n",
      "Epoch:  452 Train Loss: 0.0121 Train Acc: 0.9977 Test Loss: 3.0015 Test Acc: 0.7072\n",
      "Epoch:  453 Train Loss: 0.0115 Train Acc: 0.9981 Test Loss: 3.1280 Test Acc: 0.7117\n",
      "Epoch:  454 Train Loss: 0.0130 Train Acc: 0.9974 Test Loss: 2.8528 Test Acc: 0.7147\n",
      "Epoch:  455 Train Loss: 0.0152 Train Acc: 0.9955 Test Loss: 2.8935 Test Acc: 0.7177\n",
      "Epoch:  456 Train Loss: 0.0235 Train Acc: 0.9921 Test Loss: 2.8651 Test Acc: 0.7042\n",
      "Epoch:  457 Train Loss: 0.0200 Train Acc: 0.9936 Test Loss: 3.2947 Test Acc: 0.7027\n",
      "Epoch:  458 Train Loss: 0.0183 Train Acc: 0.9962 Test Loss: 3.1265 Test Acc: 0.7162\n",
      "Epoch:  459 Train Loss: 0.0143 Train Acc: 0.9970 Test Loss: 2.9254 Test Acc: 0.7192\n",
      "Epoch:  460 Train Loss: 0.0188 Train Acc: 0.9951 Test Loss: 3.3244 Test Acc: 0.7072\n",
      "Epoch:  461 Train Loss: 0.0165 Train Acc: 0.9962 Test Loss: 3.0748 Test Acc: 0.7102\n",
      "Epoch:  462 Train Loss: 0.0126 Train Acc: 0.9981 Test Loss: 3.2182 Test Acc: 0.6922\n",
      "Epoch:  463 Train Loss: 0.0151 Train Acc: 0.9974 Test Loss: 3.0803 Test Acc: 0.7147\n",
      "Epoch:  464 Train Loss: 0.0169 Train Acc: 0.9955 Test Loss: 2.8889 Test Acc: 0.7222\n",
      "Epoch:  465 Train Loss: 0.0143 Train Acc: 0.9959 Test Loss: 3.0190 Test Acc: 0.7132\n",
      "Epoch:  466 Train Loss: 0.0209 Train Acc: 0.9951 Test Loss: 2.9251 Test Acc: 0.7102\n",
      "Epoch:  467 Train Loss: 0.0150 Train Acc: 0.9962 Test Loss: 3.2438 Test Acc: 0.7057\n",
      "Epoch:  468 Train Loss: 0.0155 Train Acc: 0.9962 Test Loss: 3.1373 Test Acc: 0.7162\n",
      "Epoch:  469 Train Loss: 0.0134 Train Acc: 0.9966 Test Loss: 3.3040 Test Acc: 0.7042\n",
      "Epoch:  470 Train Loss: 0.0154 Train Acc: 0.9959 Test Loss: 2.9528 Test Acc: 0.7147\n",
      "Epoch:  471 Train Loss: 0.0233 Train Acc: 0.9940 Test Loss: 3.3694 Test Acc: 0.7192\n",
      "Epoch:  472 Train Loss: 0.0156 Train Acc: 0.9970 Test Loss: 2.9034 Test Acc: 0.7237\n",
      "Epoch:  473 Train Loss: 0.0133 Train Acc: 0.9970 Test Loss: 3.0565 Test Acc: 0.7102\n",
      "Epoch:  474 Train Loss: 0.0144 Train Acc: 0.9951 Test Loss: 3.3222 Test Acc: 0.7147\n",
      "Epoch:  475 Train Loss: 0.0142 Train Acc: 0.9966 Test Loss: 3.0225 Test Acc: 0.7192\n",
      "Epoch:  476 Train Loss: 0.0186 Train Acc: 0.9962 Test Loss: 2.9718 Test Acc: 0.7057\n",
      "Epoch:  477 Train Loss: 0.0154 Train Acc: 0.9940 Test Loss: 2.7456 Test Acc: 0.7327\n",
      "Epoch:  478 Train Loss: 0.0189 Train Acc: 0.9944 Test Loss: 3.1952 Test Acc: 0.7072\n",
      "Epoch:  479 Train Loss: 0.0174 Train Acc: 0.9955 Test Loss: 3.2029 Test Acc: 0.7072\n",
      "Epoch:  480 Train Loss: 0.0150 Train Acc: 0.9966 Test Loss: 3.1191 Test Acc: 0.7012\n",
      "Epoch:  481 Train Loss: 0.0149 Train Acc: 0.9962 Test Loss: 3.0488 Test Acc: 0.7252\n",
      "Epoch:  482 Train Loss: 0.0123 Train Acc: 0.9970 Test Loss: 2.9811 Test Acc: 0.7192\n",
      "Epoch:  483 Train Loss: 0.0146 Train Acc: 0.9966 Test Loss: 3.1719 Test Acc: 0.7222\n",
      "Epoch:  484 Train Loss: 0.0157 Train Acc: 0.9940 Test Loss: 3.1124 Test Acc: 0.7042\n",
      "Epoch:  485 Train Loss: 0.0198 Train Acc: 0.9951 Test Loss: 3.3566 Test Acc: 0.7222\n",
      "Epoch:  486 Train Loss: 0.0173 Train Acc: 0.9940 Test Loss: 3.1477 Test Acc: 0.7162\n",
      "Epoch:  487 Train Loss: 0.0185 Train Acc: 0.9955 Test Loss: 3.0129 Test Acc: 0.7012\n",
      "Epoch:  488 Train Loss: 0.0147 Train Acc: 0.9970 Test Loss: 3.3256 Test Acc: 0.6937\n",
      "Epoch:  489 Train Loss: 0.0189 Train Acc: 0.9951 Test Loss: 3.2541 Test Acc: 0.7072\n",
      "Epoch:  490 Train Loss: 0.0133 Train Acc: 0.9966 Test Loss: 3.1374 Test Acc: 0.7102\n",
      "Epoch:  491 Train Loss: 0.0153 Train Acc: 0.9959 Test Loss: 3.2736 Test Acc: 0.6982\n",
      "Epoch:  492 Train Loss: 0.0158 Train Acc: 0.9962 Test Loss: 3.0315 Test Acc: 0.7207\n",
      "Epoch:  493 Train Loss: 0.0213 Train Acc: 0.9944 Test Loss: 3.0888 Test Acc: 0.7117\n",
      "Epoch:  494 Train Loss: 0.0157 Train Acc: 0.9974 Test Loss: 3.0884 Test Acc: 0.7207\n",
      "Epoch:  495 Train Loss: 0.0258 Train Acc: 0.9932 Test Loss: 3.0710 Test Acc: 0.7057\n",
      "Epoch:  496 Train Loss: 0.0167 Train Acc: 0.9970 Test Loss: 3.0262 Test Acc: 0.7237\n",
      "Epoch:  497 Train Loss: 0.0132 Train Acc: 0.9966 Test Loss: 3.0134 Test Acc: 0.7102\n",
      "Epoch:  498 Train Loss: 0.0173 Train Acc: 0.9962 Test Loss: 3.1131 Test Acc: 0.7042\n",
      "Epoch:  499 Train Loss: 0.0170 Train Acc: 0.9955 Test Loss: 3.0789 Test Acc: 0.7072\n",
      "Oracle ready.\n"
     ]
    }
   ],
   "source": [
    "OracleClass = get_model(name=cfg.model.name, task=cfg.task.name)\n",
    "oracle = OracleClass(\n",
    "    num_features=datainfo.num_features,\n",
    "    num_classes=datainfo.num_classes,\n",
    "    cfg=cfg,\n",
    ").to(device)\n",
    "\n",
    "trainer = Trainer(cfg=cfg, dataset=data, model=oracle, loss=F.cross_entropy)\n",
    "trainer.start_training()\n",
    "\n",
    "oracle = trainer.model\n",
    "oracle.eval()\n",
    "\n",
    "print(\"Oracle ready.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5da0c14e",
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def predict_node(oracle, data, node_idx: int, edge_weights=None):\n",
    "    logits = oracle(\n",
    "        data.x,\n",
    "        data.edge_index,\n",
    "        edge_weights=edge_weights\n",
    "    )\n",
    "    probs = torch.softmax(logits[node_idx], dim=-1)\n",
    "    yhat = int(probs.argmax().item())\n",
    "    return yhat, probs.detach().cpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d2a28ac0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "node: 0\n",
      "pred: 3\n",
      "probs: [5.5762658e-11 3.1528758e-16 4.7524772e-08 1.0000000e+00 1.4729031e-08\n",
      " 2.9926211e-11]\n"
     ]
    }
   ],
   "source": [
    "node_idx = 0\n",
    "y_orig, p_orig = predict_node(oracle, data, node_idx)\n",
    "\n",
    "print(\"node:\", node_idx)\n",
    "print(\"pred:\", y_orig)\n",
    "print(\"probs:\", p_orig.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f6a32df8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target class: 4\n"
     ]
    }
   ],
   "source": [
    "# Cell 6\n",
    "target = (y_orig + 1) % datainfo.num_classes\n",
    "print(\"Target class:\", target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "7cb60d65",
   "metadata": {},
   "outputs": [],
   "source": [
    "node_idx = 30  # choose\n",
    "data.test_mask = [int(node_idx)]    # override to a list with 1 element"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "4e171a30",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Data(x=[449, 3703], edge_index=[2, 2242], y=[449], sub_index=5, x_projection=[64])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from src.node_level_explainer.utils.utils import build_factual_graph, check_graphs\n",
    "from src.utils.explainer import get_node_explainer\n",
    "import torch\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() and cfg.device == \"cuda\" else \"cpu\"\n",
    "oracle = oracle.to(device).eval()\n",
    "data = data.to(device)\n",
    "\n",
    "with torch.no_grad():\n",
    "    out = oracle(data.x, data.edge_index)\n",
    "    predicted_labels = torch.argmax(out, dim=1)\n",
    "    target_labels = (1 + predicted_labels) % datainfo.num_classes\n",
    "\n",
    "n_hops = len(cfg.model.hidden_layers) + 1\n",
    "node_idx = int(node_idx)\n",
    "\n",
    "factual_graph = build_factual_graph(\n",
    "    mask_index=node_idx,\n",
    "    data=data,\n",
    "    n_hops=n_hops,\n",
    "    oracle=oracle,\n",
    "    predicted_labels=predicted_labels,\n",
    "    target_labels=target_labels,\n",
    "    device=\"cpu\"\n",
    ")\n",
    "\n",
    "assert not check_graphs(factual_graph.edge_index), \"Invalid factual graph.\"\n",
    "\n",
    "cfg.device = \"cpu\"\n",
    "\n",
    "oracle = oracle.to(\"cpu\").eval()\n",
    "factual_graph = factual_graph.to(\"cpu\")\n",
    "\n",
    "ExplainerCls = get_node_explainer(\"combined\")\n",
    "explainer = ExplainerCls(cfg, datainfo)\n",
    "\n",
    "counterfactual = explainer.explain(graph=factual_graph, oracle=oracle)\n",
    "counterfactual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "ffd972bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from collections import deque\n",
    "\n",
    "def hop_distances(edge_index: torch.Tensor, center: int, num_nodes: int):\n",
    "    # build adjacency list (treat as undirected)\n",
    "    adj = [[] for _ in range(num_nodes)]\n",
    "    ei = edge_index.detach().cpu()\n",
    "    for u, v in ei.t().tolist():\n",
    "        adj[u].append(v)\n",
    "        adj[v].append(u)\n",
    "\n",
    "    dist = [-1] * num_nodes\n",
    "    dist[center] = 0\n",
    "    q = deque([center])\n",
    "    while q:\n",
    "        u = q.popleft()\n",
    "        for v in adj[u]:\n",
    "            if dist[v] == -1:\n",
    "                dist[v] = dist[u] + 1\n",
    "                q.append(v)\n",
    "    return dist  # list length=num_nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "f99cf464",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_node_feature_changes(\n",
    "    factual_graph,\n",
    "    counterfactual,\n",
    "    nodes,                      # list of local node ids\n",
    "    topk=8,\n",
    "    show_all_if_dim_le=10,\n",
    "    float_fmt=\"{:.4f}\",\n",
    "):\n",
    "    x0 = factual_graph.x.detach().cpu()\n",
    "    x1 = counterfactual.x.detach().cpu()\n",
    "    Fdim = x0.size(1)\n",
    "\n",
    "    for n in nodes:\n",
    "        d = (x1[n] - x0[n])\n",
    "        absd = torch.abs(d)\n",
    "\n",
    "        # print(f\"\\nNode(local)={n}  |  L1_change={absd.sum().item():.4f}  L2_change={torch.norm(d).item():.4f}\")\n",
    "\n",
    "        if Fdim <= show_all_if_dim_le:\n",
    "            # print all features\n",
    "            for j in range(Fdim):\n",
    "                b = float(x0[n, j].item())\n",
    "                a = float(x1[n, j].item())\n",
    "                dj = float(d[j].item())\n",
    "                if abs(dj) > 0:\n",
    "                    print(f\"  f{j:03d}: {float_fmt.format(b)} -> {float_fmt.format(a)}  (={float_fmt.format(dj)})\")\n",
    "        else:\n",
    "            # print top-k changes only\n",
    "            k = min(topk, Fdim)\n",
    "            idx = torch.topk(absd, k=k).indices.tolist()\n",
    "            for j in idx:\n",
    "                b = float(x0[n, j].item())\n",
    "                a = float(x1[n, j].item())\n",
    "                dj = float(d[j].item())\n",
    "                if abs(dj) > 0:\n",
    "                    print(f\"  f{j:03d}: {float_fmt.format(b)} -> {float_fmt.format(a)}  (={float_fmt.format(dj)})\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "618d1e5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Center(local): 5\n",
      "Hop-0 nodes: [5]\n",
      "Hop-1 nodes: [81, 189]\n",
      "Hop-2 nodes: [1, 3, 4, 9, 11, 16, 24, 30, 37, 42, 46, 48, 67, 72, 74, 78, 79, 83, 86, 87, 92, 96, 111, 113, 114, 115, 120, 128, 129, 130, 131, 132, 136, 140, 141, 144, 148, 154, 160, 167, 171, 172, 174, 180, 188, 194, 205, 208, 212, 216, 220, 224, 225, 230, 241, 252, 262, 263, 266, 267, 269, 274, 275, 280, 286, 298, 299, 301, 304, 305, 320, 322, 331, 333, 336, 342, 357, 363, 370, 371, 372, 374, 375, 379, 382, 390, 391, 392, 395, 396, 397, 398, 399, 400, 401, 402, 403, 404, 405]\n",
      "\n",
      "==================== HOP 0 (center) ====================\n",
      "  f002: 0.0000 -> 1.0000  (=1.0000)\n",
      "  f009: 0.0000 -> 1.0000  (=1.0000)\n",
      "  f013: 0.0000 -> 1.0000  (=1.0000)\n",
      "  f012: 0.0000 -> 1.0000  (=1.0000)\n",
      "  f008: 0.0000 -> 1.0000  (=1.0000)\n",
      "  f004: 0.0000 -> 1.0000  (=1.0000)\n",
      "  f014: 0.0000 -> 1.0000  (=1.0000)\n",
      "  f011: 0.0000 -> 1.0000  (=1.0000)\n",
      "  f000: 0.0000 -> 1.0000  (=1.0000)\n",
      "  f001: 0.0000 -> 1.0000  (=1.0000)\n",
      "\n",
      "==================== HOP 1 neighbors ====================\n",
      "\n",
      "==================== HOP 2 neighbors ====================\n"
     ]
    }
   ],
   "source": [
    "center_local = int(factual_graph.new_idx)\n",
    "num_nodes = factual_graph.num_nodes\n",
    "\n",
    "dist = hop_distances(factual_graph.edge_index, center_local, num_nodes)\n",
    "\n",
    "hop0 = [i for i, d in enumerate(dist) if d == 0]\n",
    "hop1 = [i for i, d in enumerate(dist) if d == 1]\n",
    "hop2 = [i for i, d in enumerate(dist) if d == 2]\n",
    "\n",
    "print(\"Center(local):\", center_local)\n",
    "print(\"Hop-0 nodes:\", hop0)\n",
    "print(\"Hop-1 nodes:\", hop1)\n",
    "print(\"Hop-2 nodes:\", hop2)\n",
    "\n",
    "print(\"\\n==================== HOP 0 (center) ====================\")\n",
    "print_node_feature_changes(factual_graph, counterfactual, hop0, topk=10)\n",
    "\n",
    "print(\"\\n==================== HOP 1 neighbors ====================\")\n",
    "print_node_feature_changes(factual_graph, counterfactual, hop1, topk=10)\n",
    "\n",
    "print(\"\\n==================== HOP 2 neighbors ====================\")\n",
    "print_node_feature_changes(factual_graph, counterfactual, hop2, topk=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a5662e4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "envs",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
